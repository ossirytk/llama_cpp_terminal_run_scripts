# llama_cpp_terminal_run_scripts
Powershell script for running llama.cpp with configs in chat mode.
This script offers model and settings menus. Config files for models, and settings.  Prompt file templates in txt format and V2 and tavern style json cards. Rerun last feature. 

Locations for resources can be set in ***main.json***. You can see setting template files in ***setting_templates***, ***prompt_templates*** and ***model_config_templates*** folders.

![Terminal image](/readme/readme.png)